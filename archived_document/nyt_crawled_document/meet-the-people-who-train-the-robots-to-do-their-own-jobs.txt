{"text": "SAN FRANCISCO \u2014 What if part of your job became teaching a computer everything you know about doing someone\u2019s job \u2014 perhaps your own? Before the machines become smart enough to replace humans, as some people fear, the machines need teachers. Now, some companies are taking the first steps, deploying artificial intelligence in the workplace and asking their employees to train the A.I. to be more human. We spoke with five people \u2014 a travel agent, a robotics expert, an engineer, a customer-service representative and a scriptwriter, of sorts \u2014 who have been put in this remarkable position. More than most, they understand the strengths (and weaknesses) of artificial intelligence and how the technology is changing the nature of work. Here are their stories. Rachel Neasham, travel agent Ms. Neasham, one of 20 (human) agents at the Boston-based travel booking app Lola, knew that the company\u2019s artificial intelligence computer system \u2014 its name is Harrison \u2014 would eventually take over parts of her job. Still, there was soul-searching when it was decided that Harrison would actually start recommending and booking hotels. At an employee meeting late last year, the agents debated what it meant to be human, and what a human travel agent could do that a machine couldn\u2019t. While Harrison could comb through dozens of hotel options in a blink, it couldn\u2019t match the expertise of, for example, a human agent with years of experience booking family vacations to Disney World. The human can be more nimble \u2014 knowing, for instance, to advise a family that hopes to score an unobstructed photo with the children in front of the Cinderella Castle that they should book a breakfast reservation inside the park, before the gates open. Ms. Neasham, 30, saw it as a race: Can human agents find new ways to be valuable as quickly as the A.I. improves at handling parts of their job? \u201cIt made me feel competitive, that I need to keep up and stay ahead of the A.I.,\u201d Ms. Neasham said. On the other hand, she said, using Harrison to do some things \u201cfrees me up to do something creative.\u201d Ms. Neasham is no ordinary travel agent. When she left the Army after serving as a captain in Iraq and Afghanistan, she wanted to work at a start-up. She joined Lola as one of its first travel agents. Knowing that part of her job was to be a role model, basically, for Harrison, she felt a responsibility for Harrison to become a useful tool. Founded in 2015 by Paul English, who also started the travel-search site Kayak, Lola was conceived as part automated chat service and part recommendation engine. Underlying it all was a type of artificial intelligence technology called machine learning. Lola was set up so that agents like Ms. Neasham didn\u2019t interact with the A.I. much, but it was watching and learning from every customer interaction. Over time, Lola discovered that Harrison wasn\u2019t quite ready to take over communication with customers, but it had a knack for making lightning-fast hotel recommendations. At first, Harrison would recommend hotels based on obvious customer preferences, like brands associated with loyalty programs. But then it started to find preferences that even the customers didn\u2019t realize that they had. Some people, for example, preferred a hotel on the corner of a street versus midblock. And in a coming software change, Lola will ask lifestyle questions like \u201cDo you use Snapchat?\u201d to glean clues about hotel preferences. Snapchat users tend to be younger and may prefer modern but inexpensive hotels over more established brands like the Ritz-Carlton. While Harrison may make the reservations, the human agents support customers during the trip. Once the room is booked, the humans, for example, can call the hotel to try to get room upgrades or recommend how to get the most out of a vacation. \u201cThat\u2019s something A.I. can\u2019t do,\u201d Ms. Neasham said. Diane Kim, interaction designer Ms. Kim is adamant: Her assistant doesn\u2019t use slang or emoji. Her assistant, Andrew Ingram, also avoids small talk and doesn\u2019t waste time on topics beside scheduling her meetings, she said. Ms. Kim isn\u2019t being tyrannical. She just knows her assistant better than most bosses, because she programmed him. Ms. Kim, 22, works as an A.I. interaction designer at x.ai, a New York-based start-up offering an artificial intelligence assistant to help people schedule meetings. X.ai pitches clients on the idea that, through A.I., they get the benefits of a human assistant \u2014 saving the time and hassle of scheduling a meeting \u2014 at a fraction of the price. It\u2019s Ms. Kim\u2019s job to craft responses for the company\u2019s assistants, who are named Andrew and Amy Ingram, or A.I. for short, that feel natural enough that swapping emails with these computer systems feels no different than emailing with a human assistant. Ms. Kim\u2019s job \u2014 part playwright, part programmer and part linguist \u2014 didn\u2019t exist before Alexa, Siri and other A.I. assistants. The job is like a translator of sorts. It is to help humans access the A.I.\u2019s superhuman capabilities like 24/7 availability and infallible memory without getting tripped up by robotic or awkward language. Even in the narrow parameters of scheduling meetings, it takes a lot of machine learning to break down emails for a computer. For example, setting a meeting for \u201cWednesday\u201d is different than setting a meeting for \u201ca Wednesday,\u201d as in any Wednesday. X.ai breaks down emails to its component parts to understand intent. The automated response is where Ms. Kim takes over. Her job is to imagine how a human assistant would arrange a meeting for the boss. For a specific task, she devises different situations \u2014 for example, what if the meeting had five attendees versus two \u2014 and then she creates a flow chart of how the email exchange would go. The goal is to schedule a meeting in as few emails as possible. With that in mind, x.ai settled on a set of personality traits for its assistants: polite, professional, friendly and clear. Sometimes, it\u2019s hard to predict what will rub people the wrong way. Early on, the A.I. assistant sent emails to potential attendees saying that the assistant would be happy to put something on the boss\u2019s \u201ccalendar,\u201d but some people found that wording to be cold, and not always appropriately deferential to the other attendees. X.ai changed the wording so that the A.I. assistant says it would be happy to \u201cfind a time\u201d that works for all attendees. Some people try to test the A.I. assistants with unusual requests. For example, people are curious what else the assistants can do and ask for help in booking hotels, flights or conference rooms (things they can\u2019t do). Others ask Amy\u2019s age, or Andrew\u2019s birthday. \u201cHow do we elegantly recover when Amy or Andrew don\u2019t know what to do?\u201d Ms. Kim said. X.ai doesn\u2019t pretend the assistants are human. But Ms. Kim still gets satisfaction when people don\u2019t realize that the assistants are robots. People ask them out on dates. They receive thank-you emails from happy customers even though, as robots, they don\u2019t need gratitude. \u201cThey\u2019re shocked and surprised that they were talking to an A.I.,\u201d she said. Dan Rubins, chief executive Mr. Rubins has a lot of grievances with lawyers. At his former job, he recalled the time when six corporate lawyers, each billing at hundreds of dollars an hour, were inspecting a contract looking for capitalization errors. It\u2019s what prompted him to create Legal Robot, a start-up that uses artificial intelligence to translate legalese into plain English. Having reviewed nearly a million legal documents, Legal Robot also flags anomalies (strange wording or clauses) in contracts. \u201cLawyers have had 400 years to innovate and change the profession, and they haven\u2019t done it,\u201d said Mr. Rubins, who is not a lawyer. \u201cIt\u2019s time for some outside help.\u201d He said legal documents are well suited to machine learning because they are highly structured and repetitive. Legal Robot tapped a vast trove of contracts prepared by human lawyers in filings with the Securities and Exchange Commission \u2014 \u201ca cesspool of legal language,\u201d Mr. Rubins said \u2014 as well as past documents from law firms who wanted to help train Legal Robot\u2019s systems. After going through a large set of documents, the company\u2019s machine learning systems start to recognize patterns indicating the words that tend to go together and those that do not. However, Mr. Rubins becomes worried when the A.I. is too confident about its results. That\u2019s often a byproduct of training the computer on too narrow a set of contracts. For example, Legal Robot trained its A.I. on thousands of employment contracts from a state that allows noncompete clauses, which restrict employees from switching to a rival company. That meant when the A.I. saw contracts from states where noncompetes aren\u2019t enforceable, it nevertheless piped up to say the clause was missing. In other words, the A.I. was missing important context. Mr. Rubins, 33, said the A.I. is good at identifying potentially vague word choices. He recently received a two-page nondisclosure agreement \u2014 it was reviewed by human lawyers \u2014 from another company containing the word \u201cshall\u201d 30 times. The A.I. pointed out that \u201cshall\u201d can be vague and advised that \u201cwill\u201d or \u201cmay\u201d are more clear, depending on the context. Mr. Rubins doesn\u2019t think A.I. will put lawyers out of business, but it may change how they work and make money. The less time they need to spend reviewing contracts, the more time they can spend on, say, advisory work or litigation. \u201cI really don\u2019t think we\u2019re going to get rid of lawyers,\u201d he said. \u201cUnfortunately, we still need them.\u201d Sarah Seiwert, customer representative It took two weeks for Ms. Seiwert to notice that her company\u2019s A.I. computer system was starting to pick up on her work patterns. Ms. Seiwert, 37, a customer representative at the online test-prep company Magoosh, answers student emails. When a question comes in, she searches a database of preapproved responses and finds the appropriate answer. There are thousands of different responses. Finding the right answer isn\u2019t as easy as it sounds. When Magoosh implemented an A.I. system in February to help its customer service team work more efficiently, Ms. Seiwert noticed that it was reading the questions and suggesting responses. If the suggestions were good, she would add a few niceties and send back a quick reply. But within two weeks, she noticed that even when she wasn\u2019t responding directly to an email, but following up to one that she had sent earlier, the software was suggesting the proper response. \u201cThat was a \u2018wow\u2019 moment for me,\u201d said Ms. Seiwert, who works from a home office in Mankato, Minn. \u201cIt\u2019s been studying and learning my patterns.\u201d As more customer service moves from phone calls to text-based conversations through chat or email, companies are looking to machine learning to help the human agents work faster. Magoosh is using software created by DigitalGenius, a London-based start-up. When an email comes into Magoosh, the system reads the email, categorizes it and routes it to the appropriate employee. After a few months, some DigitalGenius customers start to automate responses for some common questions. Basically, this happens when the A.I. has seen enough examples of how human agents handled the request that it gains confidence that its answer will be correct. Magoosh isn\u2019t there yet. But Ms. Seiwert said the software has reduced Magoosh\u2019s queue of customer requests by half, and it has made her team\u2019s goal of responding to every customer within 24 hours more manageable. Even though the A.I. is learning from the human agents, Ms. Seiwert said she doesn\u2019t foresee a future where she\u2019s out of a job. Too many questions still require a level of human intuition to know the appropriate answer. There are also times when rules need to be broken, like when customers ask for an extension on their account because of some circumstance beyond their control. \u201cI am not convinced that artificial intelligence is going to replace us,\u201d she said. \u201cYou can\u2019t program intuition, a gut instinct. So the A.I. might get very intelligent, but I hope as a human I continue to get intelligent and not stand at a standstill.\u201d Aleksandra Faust, software engineer As a senior software engineer at the self-driving car company Waymo and a robotics expert, Ms. Faust grapples with an unpredictable world. Formerly known as Google\u2019s self-driving car project, Waymo wants to build autonomous vehicles that can react properly under all kinds of unusual circumstances. Not only when drivers run red lights, but also when a child crosses an intersection riding a hoverboard while walking a dog (which happened recently). Waymo\u2019s cars have driven two million miles in the real world and billions more in computer simulations. But it\u2019s impossible to program for every event. \u201cThere\u2019s always going to be some cases that we haven\u2019t seen before,\u201d Ms. Faust said. \u201cBased on the situations it\u2019s seen, the A.I. helps the car react in situations it hasn\u2019t seen.\u201d Safety is a concern, said Ms. Faust, 43, but so is comfort. Take the process of braking at a red light. When human drivers see a red light, they tend to slow down gradually before coming to a full stop. Waymo\u2019s driverless car was hitting the brake too abruptly in a way that human drivers would do if they weren\u2019t paying attention. However, a sudden stop is dangerous because other drivers may not be paying attention. And it is jarring for the passengers. Using real-world examples of how human drivers slow to a stop from different speeds, Ms. Faust\u2019s team creates different models for the most natural way a car should brake depending on how fast it is going. \u201cOne thing we\u2019ve learned about human driving is that it\u2019s very, very complex,\u201d said Ms. Faust, who joined Waymo two years ago when it was still part of Google\u2019s research lab, X.", "source": "The New York Times", "url": "https://www.nytimes.com/2017/04/28/technology/meet-the-people-who-train-the-robots-to-do-their-own-jobs.html", "published_date": "2017-04-27T20:00:00-04:00", "section": "Technology", "updated_date": "2017-04-28T05:00:36-04:00", "item_type": "Article", "material_type_facet": "News", "created_date": "2017-04-28T05:00:36-04:00", "abstract": "Before the machines become smart enough to replace humans, as some people fear, they need to be taught.", "title": "Meet the People Who Train the Robots (to Do Their Own Jobs)"}