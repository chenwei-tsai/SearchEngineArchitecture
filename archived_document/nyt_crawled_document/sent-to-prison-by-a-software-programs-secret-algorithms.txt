{"text": "When Chief Justice John G. Roberts Jr. visited Rensselaer Polytechnic Institute last month, he was asked a startling question, one with overtones of science fiction. \u201cCan you foresee a day,\u201d asked Shirley Ann Jackson, president of the college in upstate New York, \u201cwhen smart machines, driven with artificial intelligences, will assist with courtroom fact-finding or, more controversially even, judicial decision-making?\u201d The chief justice\u2019s answer was more surprising than the question. \u201cIt\u2019s a day that\u2019s here,\u201d he said, \u201cand it\u2019s putting a significant strain on how the judiciary goes about doing things.\u201d He may have been thinking about the case of a Wisconsin man, Eric L. Loomis, who was sentenced to six years in prison based in part on a private company\u2019s proprietary software. Mr. Loomis says his right to due process was violated by a judge\u2019s consideration of a report generated by the software\u2019s secret algorithm, one Mr. Loomis was unable to inspect or challenge. In March, in a signal that the justices were intrigued by Mr. Loomis\u2019s case, they asked the federal government to file a friend-of-the-court brief offering its views on whether the court should hear his appeal. The report in Mr. Loomis\u2019s case was produced by a product called Compas, sold by Northpointe Inc. It included a series of bar charts that assessed the risk that Mr. Loomis would commit more crimes. The Compas report, a prosecutor told the trial judge, showed \u201ca high risk of violence, high risk of recidivism, high pretrial risk.\u201d The judge agreed, telling Mr. Loomis that \u201cyou\u2019re identified, through the Compas assessment, as an individual who is a high risk to the community.\u201d The Wisconsin Supreme Court ruled against Mr. Loomis. The report added valuable information, it said, and Mr. Loomis would have gotten the same sentence based solely on the usual factors, including his crime \u2014 fleeing the police in a car \u2014 and his criminal history. At the same time, the court seemed uneasy with using a secret algorithm to send a man to prison. Justice Ann Walsh Bradley, writing for the court, discussed, for instance, a report from ProPublica about Compas that concluded that black defendants in Broward County, Fla., \u201cwere far more likely than white defendants to be incorrectly judged to be at a higher rate of recidivism.\u201d Justice Bradley noted that Northpointe had disputed the analysis. Still, she wrote, \u201cthis study and others raise concerns regarding how a Compas assessment\u2019s risk factors correlate with race.\u201d In the end, though, Justice Bradley allowed sentencing judges to use Compas. They must take account of the algorithm\u2019s limitations and the secrecy surrounding it, she wrote, but said the software could be helpful \u201cin providing the sentencing court with as much information as possible in order to arrive at an individualized sentence.\u201d Justice Bradley made Compas\u2019s role in sentencing sound like the consideration of race in a selective university\u2019s holistic admissions program. It could be one factor among many, she wrote, but not the determinative one. In urging the United States Supreme Court not to hear the case, Wisconsin\u2019s attorney general, Brad D. Schimel, seemed to acknowledge that the questions in the case were substantial ones. But he said the justices should not move too fast. \u201cThe use of risk assessments by sentencing courts is a novel issue, which needs time for further percolation,\u201d Mr. Schimel wrote. He added that Mr. Loomis \u201cwas free to question the assessment and explain its possible flaws.\u201d But it is a little hard to see how he could do that without access to the algorithm itself. The company that markets Compas says its formula is a trade secret. \u201cThe key to our product is the algorithms, and they\u2019re proprietary,\u201d one of its executives said last year. \u201cWe\u2019ve created them, and we don\u2019t release them because it\u2019s certainly a core piece of our business.\u201d Compas and other products with similar algorithms play a role in many states\u2019 criminal justice systems. \u201cThese proprietary techniques are used to set bail, determine sentences, and even contribute to determinations about guilt or innocence,\u201d a report from the Electronic Privacy Information Center found. \u201cYet the inner workings of these tools are largely hidden from public view.\u201d In 1977, the Supreme Court ruled that a Florida man could not be condemned to die based on a sentencing report that contained confidential passages he was not allowed to see. The Supreme Court\u2019s decision was fractured, and the controlling opinion appeared to say that the principle applied only in capital cases. Mr. Schimel echoed that point and added that Mr. Loomis knew everything the court knew. Judges do not have access to the algorithm, either, he wrote. There are good reasons to use data to ensure uniformity in sentencing. It is less clear that uniformity must come at the price of secrecy, particularly when the justification for secrecy is the protection of a private company\u2019s profits. The government can surely develop its own algorithms and allow defense lawyers to evaluate them. At Rensselaer last month, Chief Justice Roberts said that judges had work to do in an era of rapid change. \u201cThe impact of technology has been across the board,\u201d he said, \u201cand we haven\u2019t yet really absorbed how it\u2019s going to change the way we do business.\u201d", "source": "The New York Times", "url": "https://www.nytimes.com/2017/05/01/us/politics/sent-to-prison-by-a-software-programs-secret-algorithms.html", "published_date": "2017-04-30T20:00:00-04:00", "section": "U.S.", "updated_date": "2017-05-01T05:00:25-04:00", "item_type": "Article", "material_type_facet": "News", "created_date": "2017-05-01T05:00:25-04:00", "abstract": "Using artificial intelligence in judicial decisions sounds like science fiction, but it\u2019s already happened in Wisconsin.", "title": "Sent to Prison by a Software Program\u2019s Secret Algorithms"}